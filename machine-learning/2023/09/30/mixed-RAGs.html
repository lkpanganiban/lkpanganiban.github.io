<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1 maximum-scale=1; minimum-scale=1; user-scalable=no;"> <meta content="From the previous blogpost about RAG with Llama Index, I've gone through how about developing RAGs with Llama Index, a library to create LLM applications. For this post, I have extended my experiment to mix vector and text based algorithms of vectors and bag of words." name="description"> <meta name="keywords" content="machine-learning,mlops"> <meta name="author" content="lkpanganiban"> <meta name="baseurl" content=""> <title> lkpanganiban|Mixed RAGs and Output Validation </title> <!-- favicon --> <link rel="shortcut icon" href="/static/assets/img/favicon.png"> <!-- Main CSS --> <link href="/static/assets/app-20210315.min.css" rel="stylesheet"> <link href="/static/css/custom.css" rel="stylesheet"> <!-- Main Scripts --> <script src="/static/assets/app-20210315.min.js"></script> <script src="/static/assets/blog-20210315.min.js"></script> <link rel="stylesheet" href="css/jPages.css"> <script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script> <script src="js/jPages.js"></script> <!-- Google AdSense --> <!-- <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> <script> (adsbygoogle = window.adsbygoogle || []).push({ google_ad_client: "ca-pub-6196184620210315", enable_page_level_ads: true }); </script> --> </head> <body id="page-top" class="landing-page"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6336153797582067" crossorigin="anonymous"></script> <div class="search-tool" style="position: fixed; top: 0px ; bottom: 0px; left: 0px; right: 0px; opacity: 0.95; background-color: #111111; z-index: 9999; display: none;"> <input type="text" class="form-control search-content" id="search-content" style="position: fixed; top: 60px" placeholder="Search Blog"> <div style="position: fixed; top: 16px; right: 16px; z-index: 9999;"> <img src="/static/assets/img/search/cb-close.png" id="close-btn"/> </div> </div> <div style="position: fixed; right: 16px; bottom: 20px; z-index: 9999;"> <img src="/static/assets/img/search/cb-search.png" id="search-btn" title="Double click Ctrl"/> </div> <div class="navbar-wrapper"> <nav class="navbar navbar-default navbar-fixed-top" role="navigation"> <div class="container"> <div class="navbar-header page-scroll"> <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> <a class="navbar-brand" href="/">lkpanganiban</a> </div> <div id="navbar" class="navbar-collapse collapse"> <ul class="nav navbar-nav navbar-right"> <li><a class="page-scroll" href="blog/"></a></li> <li> <a class="page-scroll" href="/blog/">Blog</a></li> <li> <a class="page-scroll" href="/python/">Python</a></li> <li> <a class="page-scroll" href="/machine-learning/">Machine Learning</a></li> <li> <a class="page-scroll" href="/database/">Database</a></li> <li> <a class="page-scroll" href="/devops/">Devops</a></li> </ul> </div> </div> </nav> </div> <div class="container-fluid"> <div id="inSlider" class="carousel slide" data-ride="carousel"> <!-- Indicators --> <ol class="carousel-indicators"> <li data-target="#inSlider" data-slide-to="0" class="active"></li> <li data-target="#inSlider" data-slide-to="1"></li> </ol> <!-- Wrapper for slides --> <div class="carousel-inner"> <div class="item active"> <div class="carousel-caption"></div> <img src="/static/assets/img/landing/header_one.webp" alt="first banner image" style="width:100%;"> </div> <div class="item"> <div class="carousel-caption"></div> <img src="/static/assets/img/landing/header_two.jpg" alt="second banner image" style="width:100%;"> </div> </div> <!-- Left and right controls --> <a class="left carousel-control" href="#inSlider" data-slide="prev"> <span class="glyphicon glyphicon-chevron-left"></span> <span class="sr-only">Previous</span> </a> <a class="right carousel-control" href="#inSlider" data-slide="next"> <span class="glyphicon glyphicon-chevron-right"></span> <span class="sr-only">Next</span> </a> </div> </div> <div class="wrapper wrapper-content animated fadeInRight article"> <div class="row"> <div class="col-lg-10 col-lg-offset-1"> <div class="ibox"> <div class="ibox-content"> <div class="pull-right"> <a class="btn btn-white btn-xs" href="/machine-learning">Machine-learning</a> </div> <div class="text-center article-title"> <span class="text-muted"><i class="fa fa-clock-o"></i> 30 Sep 2023</span> <h1> Mixed RAGs and Output Validation </h1> </div> <p>From the previous blogpost about RAG with Llama Index, I’ve gone through how about developing RAGs with Llama Index, a library to create LLM applications. For this post, I have extended my experiment to mix vector and text based algorithms of vectors and bag of words.</p> <h1 id="bag-of-words-and-retrievals">Bag of Words and Retrievals</h1> <p>In most search or indexing databases like Elasticsearch, Opensearch, and Solr, the general algorithms being used are <a href="https://en.wikipedia.org/wiki/Okapi_BM25">Best Matching (BM25)</a> and the <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">term-frequency/inverse-document-frequency (TF/IDF)</a>. It basically generates a relevance score that will be used to rank the entries in the database. Both of these fall under the bag of words type of algorithms where the existence and occurence of a word drive the relevance. The simplified steps on how bag of words pipeline are the following:</p> <ol> <li>Read and parse the data source.</li> <li>Identify the unique words in the data entry, stem words, and remove stop words. <em>Depends on the word dictionary that you will use. Some stop are the following: <code class="language-plaintext highlighter-rouge">and, are, that, then, there, such</code>.</em></li> <li>Store the unique words with the <code class="language-plaintext highlighter-rouge">id</code> of the data/document entry in an <code class="language-plaintext highlighter-rouge">index</code>. E.g. Hello -&gt; [Doc1, Doc2] and World -&gt; [Doc2]</li> <li>A prompt will be fed and parsed. <em>Removes the stopwords, tokenization, and/or implement stemming.</em></li> <li>Using the output of 4, return the entries that have a hit.</li> <li>Implement scoring using the term counts, total unique words, total words in the corpus, etc.</li> <li>Return the top <code class="language-plaintext highlighter-rouge">N</code> results and present the results to user.</li> </ol> <p>The general issue that comes up with these types of algorithms is that it does not take into account synonymous words or even the position of the term. As an example, <code class="language-plaintext highlighter-rouge">with resource</code> and <code class="language-plaintext highlighter-rouge">without resource</code> may have the same relevance score if the user is looking for <code class="language-plaintext highlighter-rouge">resource</code>; this is due the algorithm only uses the <code class="language-plaintext highlighter-rouge">resource</code> term as the input to generate the relevance. There are ways to consider this use case by setting up keywords or even modifying the score by detecting the words that will provide more context; the issue though is that you will need to hard-coding all of the use cases. That is why a lot of AI or ML workflows are using more on the vector retrieval as against to bag of words.</p> <p>The good thing about these types of algorithms though is that they are less complex by term counts meaning it is less complex and more explainable to the user. ML or embedding based retrievals introduce additional complexity by adding chunking, overlaps, data where the model was trained on, conversion to vector space, etc. Given these additional complexities, the embedding approach is computationally expensive.</p> <h1 id="vector-and-embedding-based-retrievals">Vector and Embedding-based Retrievals</h1> <p>Due to the expansion of the new thing which is ML or AI in general, the proliferation of vector stores available either proprietary or open source are on the rise and traditional database technologies are creating use cases or adding support to execute vector retrievals.</p> <p>In the my previous blogpost, to implement a sample RAG using Llama Index, it needs to convert the entries from the data source into a vector and stores it into a vector store by using embedding models. When storing these vectors the associated metadata can either be the ID or even the actual text is also stored in the vector store. The simplified steps on how to implement this pipeline are the following:</p> <ol> <li>Read and parse the data source.</li> <li>Pass the data source into the embedding model and thus generating a vector - we can call this as <code class="language-plaintext highlighter-rouge">Data Vector</code> E.g. <code class="language-plaintext highlighter-rouge">Hello World</code> =&gt; <code class="language-plaintext highlighter-rouge">[0.1021, 0.3341]</code></li> <li>Store the output into a vector store.</li> <li>A prompt or question will be fed into the vector store. This will repeat step 2. We can call this as <code class="language-plaintext highlighter-rouge">Prompt Vector</code>.</li> <li>Implement a search by comparing (clustering - e.g. KNN, cosine similarity) the distance of <code class="language-plaintext highlighter-rouge">Prompt Vector</code> with the various <code class="language-plaintext highlighter-rouge">Data Vectors</code>.</li> <li>Sort the distances.</li> <li>Return the top <code class="language-plaintext highlighter-rouge">N</code> Data Vectors together with the metadata. Present the results.</li> </ol> <p>Based on the steps, the search and retrieval is dependent on the vector computation and distances instead of term occurence. As mentioned in the bag of words section, even though this will solve the hardcoding and positional issues the vector is dependent on the data the embedded model is trained on.</p> <h1 id="vector--bag-of-words">Vector + Bag of Words</h1> <p>I am quite curious how the mixing of BM25 and vector retrieval algorithms will affect in the output result of the LLM. For this, I have implemented a <a href="https://github.com/lkpanganiban/llama-index-experiment/blob/main/implementations/llama_mix_rags_weaviate.ipynb">notebook</a> showing the difference between the two algorithms. I will be using <a href="https://www.llamaindex.ai/">Llama Index</a> and <a href="https://weaviate.io/">Weaviate</a> for this experiement. <em>Weaviate can be installed using a <a href="https://weaviate.io/developers/weaviate/installation/docker-compose">docker-compose.yml</a>.</em></p> <h1 id="experiment-notes">Experiment Notes</h1> <ul> <li>The consideration using Weaviate due to its out of the box support to BM25 and vector retrieval is good for maintainability point of view. You don’t want to have different databases for Vector and Textual searches. <em>You can use other combination of databases as you like for this like Elasticsearch, Pinecone, and PostgreSQL + PGVector.</em></li> <li>To evaluate the results, feeding the generated response to another LLM to make the decision which one to use is good for an automation point of view. If you can fine-tune the evaluator model based on the target audience will be very handy since it can help in re-wording some of the terms to the target audience e.g Non-domain audience.</li> <li>The results of the vector retrieval did not change a lot. I think this is due that we are querying something specific like steps in a handbook or instructions. <em>Maybe if we expand to other workloads and use cases like news articles or forum posts, the outputs will differ.</em></li> </ul> <hr> <div class="row"> <div class="col-md-6"> <h5 style="display: inline;">Tags:</h5> <button class="btn btn-white btn-xs" type="button">machine-learning</button> </div> <div class="col-md-6"> <div class="small text-right"> <div> </div> </div> </div> </div> <br> <div class="row"> <div class="col-lg-12"> <!-- donate --> <br> <!-- share --> <div class="a2a_kit a2a_kit_size_32 a2a_default_style"> <a class="a2a_dd" href="https://www.addtoany.com/share"></a> <a class="a2a_button_facebook"></a> <a class="a2a_button_twitter"></a> <a class="a2a_button_google_plus"></a> <a class="a2a_button_linkedin"></a> <a class="a2a_button_email"></a> <a class="a2a_button_wechat"></a> <a class="a2a_button_sina_weibo"></a> <a class="a2a_button_pocket"></a> </div> <script> var a2a_config = a2a_config || {}; a2a_config.color_main = "D7E5ED"; a2a_config.color_border = "AECADB"; a2a_config.color_link_text = "333333"; a2a_config.color_link_text_hover = "333333"; </script> <script async src="https://static.addtoany.com/menu/page.js"></script> <br> <!-- comment --> </div> </div> </div> </div> </div> </div> </div> <!-- Google analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-PQC0GXQ1JC" ></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag("js", new Date()); gtag("config", "G-PQC0GXQ1JC"); </script> <!-- GrowingIO --> </body> </html>
